{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_excel('../data/stability_paper_data/full_features.xlsx', \n",
    "                    sheet_name='Dataset with Generated Features', \n",
    "                    index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goldschmidt_TF</th>\n",
       "      <th>goldschmidt_TF_ionic</th>\n",
       "      <th>octahedral_factor</th>\n",
       "      <th>octahedral_factor_ionic</th>\n",
       "      <th>A_O</th>\n",
       "      <th>B_O</th>\n",
       "      <th>A_B</th>\n",
       "      <th>num_of_atoms_host_Asite0</th>\n",
       "      <th>shannon_radii_host_Asite0</th>\n",
       "      <th>host_Asite0_Ionic Radius (angstroms)</th>\n",
       "      <th>...</th>\n",
       "      <th>Bsite_NdUnfilled_range</th>\n",
       "      <th>Bsite_NdValence_range</th>\n",
       "      <th>Bsite_NfUnfilled_range</th>\n",
       "      <th>Bsite_NfValence_range</th>\n",
       "      <th>Bsite_NpUnfilled_range</th>\n",
       "      <th>Bsite_NpValence_range</th>\n",
       "      <th>Bsite_NsUnfilled_range</th>\n",
       "      <th>Bsite_NsValence_range</th>\n",
       "      <th>Bsite_NUnfilled_range</th>\n",
       "      <th>EnergyAboveHull</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.021823</td>\n",
       "      <td>0.976828</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>2.86125</td>\n",
       "      <td>1.980</td>\n",
       "      <td>2.04125</td>\n",
       "      <td>7</td>\n",
       "      <td>1.440</td>\n",
       "      <td>1.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.747707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.987385</td>\n",
       "      <td>0.889057</td>\n",
       "      <td>0.378571</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>2.69500</td>\n",
       "      <td>1.930</td>\n",
       "      <td>1.82500</td>\n",
       "      <td>4</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>106.702335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.976009</td>\n",
       "      <td>0.908360</td>\n",
       "      <td>0.452857</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>2.80750</td>\n",
       "      <td>2.034</td>\n",
       "      <td>2.04150</td>\n",
       "      <td>6</td>\n",
       "      <td>1.340</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171.608093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.026809</td>\n",
       "      <td>0.865275</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.492857</td>\n",
       "      <td>2.73000</td>\n",
       "      <td>1.880</td>\n",
       "      <td>1.81000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>284.898190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.909001</td>\n",
       "      <td>0.916519</td>\n",
       "      <td>0.452857</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>2.61475</td>\n",
       "      <td>2.034</td>\n",
       "      <td>1.84875</td>\n",
       "      <td>6</td>\n",
       "      <td>1.083</td>\n",
       "      <td>1.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270.007913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 963 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       goldschmidt_TF  goldschmidt_TF_ionic  octahedral_factor  \\\n",
       "index                                                            \n",
       "1            1.021823              0.976828           0.414286   \n",
       "2            0.987385              0.889057           0.378571   \n",
       "3            0.976009              0.908360           0.452857   \n",
       "4            1.026809              0.865275           0.342857   \n",
       "5            0.909001              0.916519           0.452857   \n",
       "\n",
       "       octahedral_factor_ionic      A_O    B_O      A_B  \\\n",
       "index                                                     \n",
       "1                     0.385714  2.86125  1.980  2.04125   \n",
       "2                     0.464286  2.69500  1.930  1.82500   \n",
       "3                     0.392857  2.80750  2.034  2.04150   \n",
       "4                     0.492857  2.73000  1.880  1.81000   \n",
       "5                     0.392857  2.61475  2.034  1.84875   \n",
       "\n",
       "       num_of_atoms_host_Asite0  shannon_radii_host_Asite0  \\\n",
       "index                                                        \n",
       "1                             7                      1.440   \n",
       "2                             4                      1.200   \n",
       "3                             6                      1.340   \n",
       "4                             4                      1.200   \n",
       "5                             6                      1.083   \n",
       "\n",
       "       host_Asite0_Ionic Radius (angstroms)  ...  Bsite_NdUnfilled_range  \\\n",
       "index                                        ...                           \n",
       "1                                      1.26  ...                       0   \n",
       "2                                      1.13  ...                       0   \n",
       "3                                      1.00  ...                       0   \n",
       "4                                      1.13  ...                       0   \n",
       "5                                      1.03  ...                       0   \n",
       "\n",
       "       Bsite_NdValence_range  Bsite_NfUnfilled_range  Bsite_NfValence_range  \\\n",
       "index                                                                         \n",
       "1                          0                       0                      0   \n",
       "2                          0                       0                      0   \n",
       "3                          0                       0                      0   \n",
       "4                          0                       0                      0   \n",
       "5                          0                       0                      0   \n",
       "\n",
       "       Bsite_NpUnfilled_range  Bsite_NpValence_range  Bsite_NsUnfilled_range  \\\n",
       "index                                                                          \n",
       "1                           0                      0                       0   \n",
       "2                           0                      0                       0   \n",
       "3                           0                      0                       0   \n",
       "4                           0                      0                       0   \n",
       "5                           0                      0                       0   \n",
       "\n",
       "       Bsite_NsValence_range  Bsite_NUnfilled_range  EnergyAboveHull  \n",
       "index                                                                 \n",
       "1                          0                      0        29.747707  \n",
       "2                          0                      0       106.702335  \n",
       "3                          0                      0       171.608093  \n",
       "4                          0                      0       284.898190  \n",
       "5                          0                      0       270.007913  \n",
       "\n",
       "[5 rows x 963 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw = pd.read_excel('1-s2.0-S2352340918305092-mmc2.xlsx', sheet_name='Dataset with Generated Features')\n",
    "df = raw.copy()\n",
    "df.drop(['Material Composition', 'Formation_energy'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1929, 792)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# remove features with 0 variance\n",
    "vt = VarianceThreshold()\n",
    "vt.fit(df)\n",
    "df = df.loc[:, vt.variances_ > 1e-8 ]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1929, 397)\n"
     ]
    }
   ],
   "source": [
    "init_x = df.loc[:, df.columns !='EnergyAboveHull']\n",
    "init_y = df.loc[:, 'EnergyAboveHull']\n",
    "\n",
    "# remove low correlated features\n",
    "low_corr = []\n",
    "for col in init_x.columns:\n",
    "    if abs(init_x[col].corr(init_y)) < 1e-2:\n",
    "        low_corr.append(col)\n",
    "        \n",
    "from collections import defaultdict\n",
    "corr_df = init_x.corr()\n",
    "# get features that have correlation > 0.95 \n",
    "def high_corr(corr):\n",
    "    raw_corrs = defaultdict(float)\n",
    "    for col in corr.columns:\n",
    "        index = corr[col].index\n",
    "        for pos in range(len(index)):\n",
    "            if np.abs(corr[col][pos]) >= 0.90 and index[pos] != col:\n",
    "                raw_corrs[(col, index[pos])] =  corr[col][pos]\n",
    "    \n",
    "    # remove duplicates by score\n",
    "    result = defaultdict(float)\n",
    "    for key,value in raw_corrs.items():\n",
    "        if value not in result.values():\n",
    "            result[key] = value\n",
    "            \n",
    "    return result\n",
    "\n",
    "high_corrs = high_corr(corr_df)\n",
    "\n",
    "# keep only one of the features that are highly correlated\n",
    "# keep the one that has highest correlation with target\n",
    "df.drop(low_corr, axis=1, inplace=True)\n",
    "\n",
    "for key, val in high_corrs.items():\n",
    "    try: \n",
    "        if np.abs(df[key[0]].corr(df['EnergyAboveHull'])) > np.abs(df[key[1]].corr(df['EnergyAboveHull'])):\n",
    "            df = df.loc[:, df.columns != key[1]]\n",
    "        else: \n",
    "            df = df.loc[:, df.columns != key[0]]\n",
    "    except KeyError:\n",
    "        continue\n",
    "        \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = df.copy()\n",
    "class_df['class'] = 0\n",
    "class_df.loc[class_df['EnergyAboveHull'] > 40, 'class'] = 1\n",
    "class_df.drop(['EnergyAboveHull'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1362\n",
       "0     567\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_df['class'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class = class_df.loc[:, class_df.columns !='class'].copy()\n",
    "y_class = class_df.loc[:, 'class'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression, f_classif, SelectKBest, RFECV, RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class)\n",
    "\n",
    "f_values, p_values = f_classif(X_train_class, y_train_class)\n",
    "\n",
    "pval_df = pd.DataFrame({'features': X_class.columns, 'p_val': p_values})\n",
    "pval_df = pval_df[pval_df['p_val'] >= 0.05].copy()\n",
    "\n",
    "class_df.drop(pval_df['features'], axis=1, inplace=True)\n",
    "X_class.drop(pval_df['features'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfe_gb = RFECV(GradientBoostingClassifier(random_state=0), scoring='f1')\n",
    "# rfe_gb.fit(X_train_class, y_train_class)\n",
    "# print('Number of Features:',  rfe_gb.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV, KFold, StratifiedKFold,RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "# rfe_et_class = RFECV(ExtraTreesClassifier(random_state=0), cv=StratifiedKFold(5, shuffle=True, random_state=0), scoring='f1')\n",
    "# rfe_et_class.fit(X_train_class, y_train_class)\n",
    "# print('Number of Features:',  rfe_et_class.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 217\n",
      "CPU times: user 1min 20s, sys: 391 ms, total: 1min 20s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rfe_tree = RFECV(DecisionTreeClassifier(random_state=0), cv=StratifiedKFold(5, shuffle=True, random_state=0), scoring='f1')\n",
    "rfe_tree.fit(X_train_class, y_train_class)\n",
    "print('Number of Features:',  rfe_tree.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tree = X_class.iloc[:, rfe_tree.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_composition_features_1(X, composition_series):\n",
    "    composition_df = composition_series.to_frame('composition')\n",
    "    \n",
    "    a_ref_compositions = ['Ba', 'Pr', 'Y', 'La', 'Sr',]\n",
    "    b_ref_compositions = ['Fe', 'V', 'Ni', 'Mn',]\n",
    "    \n",
    "    def _ref_composition(composition,\n",
    "                         ref_compositions):\n",
    "        for c in ref_compositions:\n",
    "            if c in composition:\n",
    "                return c\n",
    "        return 'Other'\n",
    "    \n",
    "    composition_df['a_category'] = composition_df['composition'].apply(\n",
    "        lambda x: _ref_composition(x, a_ref_compositions))\n",
    "    composition_df['b_category'] = composition_df['composition'].apply(\n",
    "        lambda x: _ref_composition(x, b_ref_compositions))\n",
    "    \n",
    "    composition_df = composition_df.assign(\n",
    "        **pd.get_dummies(composition_df['a_category'], prefix='a_'))\n",
    "    composition_df = composition_df.assign(\n",
    "        **pd.get_dummies(composition_df['b_category'], prefix='b_'))\n",
    "    \n",
    "    additional_features = composition_df.drop(\n",
    "        ['composition', 'a_category', 'b_category'], axis=1)\n",
    "    X_new = pd.concat((X, additional_features), axis=1)\n",
    "    return X_new\n",
    "    \n",
    "    \n",
    "def append_composition_features_2(X, composition_series):\n",
    "    \"\"\"\n",
    "    Indicator feature for whether A-site includes 'Pr', 'La', 'Y'\n",
    "    Another indicator feature for when A-site includes 'Pr' or 'Y' and B-site includes 'V'\n",
    "    \"\"\"\n",
    "    composition_df = composition_series.to_frame('composition')\n",
    "    \n",
    "    def _get_aside_feature(composition):\n",
    "        for c in ['Pr', 'La', 'Y']:\n",
    "            if c in composition:\n",
    "                return 1\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def _get_bside_feature(composition):\n",
    "\n",
    "        if 'V' not in composition:\n",
    "            return 0\n",
    "\n",
    "        for c in ['Pr', 'Y']:\n",
    "            if c in composition:\n",
    "                return 1\n",
    "\n",
    "        return 0\n",
    "    \n",
    "    composition_df['a_ind'] = composition_df['composition'].apply(_get_aside_feature)\n",
    "    composition_df['b_ind'] = composition_df['composition'].apply(_get_bside_feature)\n",
    "    \n",
    "    additional_features = composition_df[['a_ind', 'b_ind']]\n",
    "    X_new = pd.concat((X, additional_features), axis=1)\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional_features = composition_df.drop(['composition', 'a_category', 'b_category'], axis=1)\n",
    "# additional_features = composition_df[['a_ind', 'b_ind']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "xgb = xgboost.XGBClassifier(random_state=0, n_estimators=400, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.7481017428167689\n",
      "f1: 0.8125096008538227\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def oversample(sampling_strategy, X, y):\n",
    "    xtrains = []\n",
    "    ytrains = []\n",
    "    xtests = []\n",
    "    ytests = []\n",
    "    f1scores=[]\n",
    "    acc = []\n",
    "    if sampling_strategy == 'smote':\n",
    "        sampler = SMOTE()\n",
    "    elif sampling_strategy == 'over':\n",
    "        sampler = RandomOverSampler(random_state=828)\n",
    "        \n",
    "    kf = StratifiedKFold(n_splits=5)\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, y_train = X[train_index], y.iloc[train_index]\n",
    "        X_test, y_test = X[test_index], y.iloc[test_index]\n",
    "        X_train_oversampled, y_train_oversampled = sampler.fit_sample(X_train, y_train)\n",
    "        xgb.fit(X_train_oversampled, y_train_oversampled)\n",
    "        y_pred = xgb.predict(X_test)\n",
    "        acc.append(xgb.score(X_test, y_test))\n",
    "        f1scores.append(f1_score(y_test, y_pred))\n",
    "        #xtrains.append(X_train_oversampled)\n",
    "        #ytrains.append(y_train_oversampled)\n",
    "        #xtests.append(X_test)\n",
    "        #ytests.append(y_test)\n",
    "    # return np.array(xtrains), np.array(ytrains), np.array(xtests), np.array(ytests)\n",
    "    return acc, f1scores\n",
    "\n",
    "#xtrains, ytrains, xtests, ytests = oversample('over', X_class.to_numpy(), y_class)\n",
    "acc, f1scores = oversample('over', X_tree.to_numpy(), y_class)\n",
    "print('Acc: ' + str(np.mean(acc)))\n",
    "print('f1: ' + str(np.mean(f1scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1929, 228), (1929, 219))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composition_series = raw['Material Composition']\n",
    "\n",
    "X_tree_1 = append_composition_features_1(X_tree, composition_series)\n",
    "X_tree_2 = append_composition_features_2(X_tree, composition_series)\n",
    "\n",
    "X_tree_1.shape, X_tree_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composition Feature 1:\n",
      "Acc: 0.7522495121458853\n",
      "f1: 0.8163506451889386\n",
      "\n",
      "\n",
      "Composition Feature 2:\n",
      "Acc: 0.7512213175425612\n",
      "f1: 0.8155965844759157\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Composition Feature 1:')\n",
    "acc, f1scores = oversample('over', X_tree_1.to_numpy(), y_class)\n",
    "print('Acc: ' + str(np.mean(acc)))\n",
    "print('f1: ' + str(np.mean(f1scores)))\n",
    "print('\\n')\n",
    "\n",
    "print('Composition Feature 2:')\n",
    "acc, f1scores = oversample('over', X_tree_2.to_numpy(), y_class)\n",
    "print('Acc: ' + str(np.mean(acc)))\n",
    "print('f1: ' + str(np.mean(f1scores)))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampled train dataset for the first fold is xtrains[0]\n",
    "# ytrains[0] are the corresponding labels for xtrains[0]\n",
    "# firstfoldtrain = pd.DataFrame(xtrains[0])\n",
    "# firstfoldtrain['class'] = ytrains[0]\n",
    "# firstfoldtrain.columns = class_df.columns\n",
    "# firstfoldtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_reg = df.loc[:, df.columns !='EnergyAboveHull']\n",
    "# y_reg = df.loc[:, 'EnergyAboveHull']\n",
    "\n",
    "# X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg)\n",
    "\n",
    "# # remove statistically insignificant features based on lin reg\n",
    "# f_values, p_values = f_regression(X_train_reg, y_train_reg)\n",
    "# pval_df = pd.DataFrame({'features': X_reg.columns, 'p_val': p_values})\n",
    "# pval_df = pval_df[pval_df['p_val'] >= 0.05]\n",
    "\n",
    "# X_reg.drop(pval_df['features'], axis=1, inplace=True)\n",
    "# X_reg.shape\n",
    "\n",
    "# # apply inverse hyperbolic sine transform to normalize data\n",
    "# # logarithmic apply to test data as well because model is fitted to log data\n",
    "# y_reg_log = y_reg.apply(lambda x: np.arcsinh(x))\n",
    "\n",
    "# X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg_log)\n",
    "\n",
    "# %%time\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "\n",
    "# rfe_log = RFECV(DecisionTreeRegressor(random_state=0), cv=KFold(10, shuffle=True), scoring='r2')\n",
    "# rfe_log.fit(X_train_reg, y_train_reg)\n",
    "# print('Number of Features:',  rfe_log.n_features_)\n",
    "\n",
    "# X_dtr = X_reg.iloc[:, rfe_log.support_]\n",
    "# X_dtr_train, X_dtr_test, y_dtr_train, y_dtr_test = train_test_split(X_dtr, y_reg_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, ExtraTreesRegressor\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "# grid = RandomizedSearchCV(ExtraTreesRegressor(random_state=0), param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# grid.fit(X_dtr_train, y_dtr_train)\n",
    "# grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ExtraTreesRegressor(random_state=0, max_depth=20, n_estimators=1800, min_samples_split=2, min_samples_leaf=1,\n",
    "                          max_features='auto', bootstrap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample for regression\n",
    "import smogn\n",
    "\n",
    "def oversample_reg(df, model):\n",
    "    dftrains=[]\n",
    "    dftests=[]\n",
    "    r2 = []\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        try:\n",
    "            df_train = df.iloc[train_index]\n",
    "            df_test = df.iloc[test_index]\n",
    "            df_smogn = smogn.smoter(data = df_train.reset_index(drop=True), y = 'EnergyAboveHull')\n",
    "            X_train_smogn = df_smogn.loc[:, df_smogn.columns!='EnergyAboveHull']\n",
    "            y_train_smogn = df_smogn['EnergyAboveHull']\n",
    "            X_test = df_test.loc[:, df_test.columns!='EnergyAboveHull']\n",
    "            y_test = df_test['EnergyAboveHull']\n",
    "            model.fit(X_train_smogn, y_train_smogn)\n",
    "            r2.append(model.score(X_test, y_test))\n",
    "        #dftrains.append(df_smogn)\n",
    "        #dftests.append(df_test)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "    #return dftrains, dftests\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_matrix: 100%|##########| 201/201 [03:03<00:00,  1.09it/s]\n",
      "synth_matrix: 100%|##########| 201/201 [00:12<00:00, 16.15it/s]\n",
      "r_index: 100%|##########| 168/168 [00:05<00:00, 32.42it/s]\n",
      "dist_matrix: 100%|##########| 194/194 [02:50<00:00,  1.14it/s]\n",
      "synth_matrix: 100%|##########| 194/194 [00:11<00:00, 16.29it/s]\n",
      "r_index: 100%|##########| 190/190 [00:06<00:00, 30.23it/s]\n",
      "dist_matrix: 100%|##########| 198/198 [02:59<00:00,  1.11it/s]\n",
      "synth_matrix: 100%|##########| 198/198 [00:12<00:00, 16.28it/s]\n",
      "r_index: 100%|##########| 177/177 [00:05<00:00, 32.58it/s]\n",
      "dist_matrix: 100%|##########| 191/191 [02:51<00:00,  1.11it/s]\n",
      "synth_matrix: 100%|##########| 191/191 [00:17<00:00, 10.77it/s]\n",
      "r_index: 100%|##########| 7/7 [00:00<00:00, 23.12it/s]\n",
      "dist_matrix: 100%|##########| 201/201 [03:01<00:00,  1.11it/s]\n",
      "synth_matrix: 100%|##########| 201/201 [00:11<00:00, 17.37it/s]\n",
      "r_index: 100%|##########| 168/168 [00:04<00:00, 33.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17min 44s, sys: 3.99 s, total: 17min 48s\n",
      "Wall time: 17min 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6343180021942851"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "r2 = oversample_reg(df, tree)\n",
    "np.mean(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1929, 397), (1929, 408))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = append_composition_features_1(df, composition_series)\n",
    "df.shape, df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_matrix: 100%|##########| 201/201 [03:11<00:00,  1.05it/s]\n",
      "synth_matrix: 100%|##########| 201/201 [00:13<00:00, 15.44it/s]\n",
      "r_index: 100%|##########| 168/168 [00:05<00:00, 28.42it/s]\n",
      "dist_matrix: 100%|##########| 194/194 [03:01<00:00,  1.07it/s]\n",
      "synth_matrix: 100%|##########| 194/194 [00:12<00:00, 15.79it/s]\n",
      "r_index: 100%|##########| 190/190 [00:06<00:00, 30.39it/s]\n",
      "dist_matrix: 100%|##########| 198/198 [03:10<00:00,  1.04it/s]\n",
      "synth_matrix: 100%|##########| 198/198 [00:12<00:00, 16.08it/s]\n",
      "r_index: 100%|##########| 177/177 [00:05<00:00, 30.17it/s]\n",
      "dist_matrix: 100%|##########| 191/191 [02:56<00:00,  1.08it/s]\n",
      "synth_matrix: 100%|##########| 191/191 [00:19<00:00,  9.81it/s]\n",
      "r_index: 100%|##########| 7/7 [00:00<00:00, 45.52it/s]\n",
      "dist_matrix: 100%|##########| 201/201 [03:16<00:00,  1.02it/s]\n",
      "synth_matrix: 100%|##########| 201/201 [00:11<00:00, 16.91it/s]\n",
      "r_index: 100%|##########| 168/168 [00:05<00:00, 33.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 41s, sys: 4.91 s, total: 18min 46s\n",
      "Wall time: 18min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7397315296261919"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# added composition features \n",
    "r2 = oversample_reg(df_1, tree)\n",
    "np.mean(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
